## Storage Services

> [!info] FSx, EFS and advanced S3 topics
### FSx

#### FSx for Windows

> tldr; Managed Windows File Server in AWS

==Exam: Windows, SMB, VSS, Integration with AD = FSx for Windows==

Requires Active Directory (but this doesn't have to be in AWS)

Has on-demand and Scheduled backup

Can be accessed over VPC, Peering, VPN or Direct Connect

Offers features like:
- Volume Shadow copy
- De-duplication
- KMS at-rest encryption
- Enforced encryption in-transit

#### FSx for Lustre

> tldr; Extreme performance scenarios

==Exam: Big data, High Performance, POSIX style permissions = FSx for Lustre==

100's GB/s + sub millisecond latency

Two deployment types: 

Min 1.2TiB, then increments of 2.4TiB

Scratch (short term, no ha, no replication, fast)
  - 200MB/s per TiB
  - Larger FS increases risk of failure, think RAID0

Persistent (longer term, HA **in one AZ only** for perf reasons, self-healing)
  - 50, 100, 200MB/s per TiB with credit system (similar to EBS volume)
  - AZ fails, we could still lose data

Lustre includes in-memory cache

Automatic backup option to S3, up to 35 days retention

Accessible over VPN or DX

FSx for Lustre can can be configured with S3 repository
- Lazy loading - when the object is first accessed, it is copied into FSx for Lustre

### EFS

> tldr; network based filesystem that can be mounted in linux ec2 instances

==Exam: Closer to 'stateless': not local storage so the data isn't lost when an instance is destroyed, Linux only!==

POSIX permissions - Linux Perms

NFSv4
- FS can be mounted on multiple instances at once!

Private service, but can be accessed using VPN, DX

Mount targets: Need to have one in each AZ for HA

General Purpose or Max I/O storage

Bursting vs Provisioned Throughput modes

Standard and Infrequent Access (IA) classes, like S3

![[Images/image-20230927164104384.png]]
### Simple Storage Service (S3)

#### S3 Object Storage Classes

###### S3 Standard
- Replicated across 3AZs
- 11x9s of durability
- 200 OK return status means data has been stored durably within S3
- $costs: per GB stored, Transfer out, Price per 1000 requests
- ==Exam: Use for frequency accessed data that is important and non-replaceable==
- 30 day minimum before IA

###### S3 Standard-IA
- Same durability as S3
- 11x9s of durability
- ==Exam: Use for long lived data which is critical and where access is infrequent (say 1x per month)==
- $costs: Storage cost is about half the cost of S3 Standard, but higher 
  - Good if we don't need to access data often but...
  - New cost component: retrieval (bad if we need to access frequently)
  - Minimum duration of 30 days (bad for anything short term)
  - Minimum charge of 128KB per object (bad for tiny objects)

###### S3 One Zone-IA
- Data on stored in one AZ only
- 11x9s of durability as long as AZ doesn't die
- ==Exam: Used for long lived data which is non-critical and where access is infrequent (say 1x per month)==
- $costs: Lower storage cost
- Still has retrieval fee
- 30 day minimum, 128KB size

###### S3 Glacier - Instant
- 3AZs
- 11x9s of durability
- Instant access to data
- $costs: More expensive retrieval costs
- 90 day minimum, 128KB size

###### S3 Glacier - Flexible
- 3AZs
- 11x9s of durability
- "Think of this as cold objects"
	- Can't be made public
- $costs: About 1/6 cost of Standard S3
	- 90 day minimum, 40KB size
	- Retrieval process is a job that takes time and costs $
	- First byte latency: minutes to hours
	- When retrieved they are temporarily copied to S3-IA location
		- Expedited: 1-5 mins
		- Standard 3-5 hours
		- Bulk 5-12

###### S3 Glacier - Deep Archive

- 3AZs
- 11x9s of durability
- "Think of this as frozen objects"
  - Suited for long term archival
- $costs: About 1/6 cost of Standard S3
  - 90 day minimum, 40KB size
  - Retrieval process is a job that takes time and costs $
  - First byte latency: hours to days
  - When retrieved they are temporarily copied to S3-IA location
    - Standard 12 hours
    - Bulk 48 hours

###### S3 Intelligent-Tiering

> tldr; Monitoring & Automated Migration process to other tiers

Handles moving objects between classes for you
- Frequent Access -> Infrequent Access -> Archive Instant Access -> Archive Access -> Deep Archive
- Intelligent-Tiering monitors and moves objects not object for 30 days to IA tier, and eventually to the other tiers if configured

Retrieval costs are a bit different
- Don't pay for the retrieval fees for movement between tiers
- However we do pay a management fee

###### S3 Lifecycle Configuration

> tldr; Set of rules + actions which apply to bucket or group of objects

Transition Actions
- e.g. transition from S3 Standard to S3 IA after 30 days

Expiration Actions
- Delete objects after a certain time period

Have to be careful handling versioned buckets

No rules based on frequency of access
- This feature is handled by Intelligent-Tiering

Usually one tier can be migrated to the next
- Except One Zone-IA can't move to Instant Retrieval

![[Images/image-20230927175117640.png]]

Considerations:
- Can't move up tiers only down
- Be careful of minimum sizes, can cost more
- 30 day minimum on S3 standard before it can do into the IA tiers
  - This doesn't apply via the console, but it does via lifecycle actions
- *A single rule* cannot transition to Standard-IA or One-Zone-IA and THEN to glacier classes with 30 days (can achieve this with multiple rules)

#### S3 Replication

> tldr; replicating from a source bucket to a target bucket

Cross Region Replication (CRR)
Same Region Replication (SRR)

Buckets can be in different accounts

Replication config
+ Target bucket
+ IAM role (S3 service will assume it)
+ Role has perms to read on source side, plus replicate on target side

In the same account:
* IAM service is trusted by both buckets

For different accounts:
- Role is not by default trusted by dest. account
- So we have to add a bucket policy to allow role from external account to write stuff

Options:
- All objects or subset
- Storage class on destination
- Owner of object on destination bucket
	- Default is source account
	- In diff accounts, the dest account won't be able to read them!
	- We can override so the dest. account owns the objects
- Replication Time Control (RTC) adds a 15 minute SLA
	- also costs more

Important points:
- Replication is not retroactive
- When enabled, you get a choice to replicate existing objects (or not)
- Versioning required on both buckets
- One way replication process only (source->dest)
- Recent feature: Bi-directional replication, needs configuring
- Can handle un-encrypted or encrypted with SSE-S3, SSE-KMS with extra config
- Source bucket owner needs permissions to objects
- No system events, Glacier or Glacier Deep Archive
- No deletes, by default
	- Delete markers are not replication unless specifically enabled

==Delete markers are how deletes are handled in versioned buckets==

Why would you want this?
- SRR: Replicate prod data to test
- SRR: Log aggregation
- SRR: Resilience where data needs to be stored in local region only
- CRR: Global resilience improvements
- CRR: Latency reduction
#### S3 Encryption

###### S3 Server Side Encryption

> tldr; buckets aren't encrypted, objects are

Encryption options
- Client-Side Encryption - you handle all the encryption
- SSE-C -  Customer provided keys
  - Customer manages keys / S3 manages encryption
  - Offloads the encryption process to AWS
  - Choose this if you need to manage keys but trust AWS
- SSE-S3 - Amazon S3-Managed Keys (default)
  - AWS handles keys and encryption process
  - You just provide the data
  - If you see AES256 think SSE-S3
  - When it hits S3 it's encrypted by a unique per key per object
  - S3 Key (used internally) -> used to encrypt per object key
  - Limitation: 
    - No control over keys used (might need to do this for strong regulation)
    - Can't rotate keys
    - Role separation issues: Full S3 administrator can also decrypt data
- SSE-KMS - KMS Keys stored in AWS Key Management Service
  - S3 and KMS work together
  - You create and manage the encryption key via KMS
  - Still has a per-object key
  - KMS keys can only encrypt up to 4KB in size, so KMS key is used to generate a different key without that limitation
  - We have control over the KMS keys + rotation
  - And logging and auditing on key itself with Cloudtrail
  - S3 Admins can't access the KMS key
    - Unless they are explicitly given perms

Note: Server side encryption recently became mandatory

![[Images/image-20230928174312819.png]]
###### S3 Bucket Keys

> tldr; With KMS, each object uses a unique DEK = lot of KMS requests... doesn't scale!

Cost goes up based on number of S3 objects.

Also KMS throttles requests after a point

Bucket Keys: KMS key generates a time limited 'bucket key' which is used for a limited time to encrypt objects in a bucket

Not retroactive - starts from when you turn it on

Cloudtrail logs now show the bucket ARN instead of object ARN

You'll also see fewer KMS requests in Cloudtrail logs

Work with SRR and CRR (replication)
- Some nuances with S3 bucket keys and replication
- Can lead to differences in 'Etag' (entity tag, hash of the object)
- More info: https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-key.html

###### S3 Presigned URLs

> tldr; give someone access to an object in your bucket in a secure way

How would we do this without Presigned URLS?
- Create user creds?
- Provide AWS creds?
- Make Public?

All have problems...

Presigned URL gives temporary access to an object a bucket
- Can be used for PUT and GETs

Scenario:
- Say we have a private bucket
- We can create an IAM user for an application iamapp1
- Application can initiate request to S3 to generate presigned URL
- User can then access object via the url even though it's private

Exam: You can create a presigned URL for an object you have no access to
- If you don't have access, the presigned URL won't have access either
- When using presigned URL, you're accessing it based on the identity which generated it
- Access denied could mean the generating ID **never had access**, or **doesn't now**
- Don't generate presigned URL when using an STS role
	- Once the temporary creds expire, your url will stop working

###### S3 Select & Glacier Select

> tldr; a way to retrieve partial objects from s3 or glacier

S3 can store huge objects up to 5TB

We often want to retrieve the whole object

If we filter on the client side, we still have to retrieve the whole object first...

But what if we only need part of the object... like a download resuming thingee

S3/Glacier select uses SQL-Like statements to select part of the object

Benefit: reduced cost and faster speed

###### S3 Access Points

> tldr; imagine a bucket with billions of objects and prefixes... the bucket policy would be a nightmare

Access points make this more manageable

No longer managed a monolithic entity

Access points are like 'views' on the bucket

You get a new endpoint for each access point (you don't use the default S3 endpoint)

This is a unique DNS name

```aws s3control create-access-point```

Access points can be restricted from VPC only
- Requires a VPCe and endpoint policies

Extra reading (not needed for exam) https://docs.aws.amazon.com/AmazonS3/latest/dev/creating-access-points.html#access-points-policies

###### S3 Object Lock

> tldr; WORM (write once read many) architecture for buckets (no delete, no overwrite)

You can only enable this on new buckets
- Requires versioning and cannot be disabled
- Individual versions are locked
- Bucket can have default object lock settings
- Retention period is in Days or Years...

**Compliance mode:** Objects can't be changed + Retention period cannot be changed for the duration even by root user until retention period expires
- Use when: You need to keep data for 3 years by law, use this

**Governance mode:** s3BypassGovernanceRetention can get around restrictions
- Note: Console does have this permission so can make changes via it
- Use when: you're testing, or the rules aren't as strict

**Legal Hold:** On or Off - no changes or deletes until removed
- Extra permission required: s3:PutObjectLegalHold is required to add or remove legal hold
- Can use multiple modes e.g. Legal Hold + Governance Mode together
#### Macie

> tldr; automated way to discover data security issues such as credit card info

Rules:
- Managed data identifiers
- ML Patterns for common sensitive data, pre-created
- Or you can build specific ones for your business based on regex
	- Could be something like an employee id
Policy findings:
Sensitive data findings: 
- S3Object/Credentials, S3Object/CustomIdentifier, S3Object/Financial etc

Policy findings:
- Say a bucket was encrypted before Macie enabled, then encryption got disabled

The standard identifiers:
https://docs.aws.amazon.com/macie/latest/user/managed-data-identifiers.html

#### EBS

> tldr; block storage presented over the network
##### General Purpose SSD

###### GP2

> tldr; gp2 was the first version of aws storage which operates on a 'credit system'

Volume size can be 1GB-16TB

250MiB/s max bandwidth.

fyi One IOP is 16KB

An IO credit is good for 1x16KB chunk of data. Transferring a 160KB file = 10IOPS.

Any reads AND writes drain the credits.

Once the credits run out we have no more IOPS. But... there's a base credit refill rate ~100IOPS per second minimum so we can keep hammering the disk at 100IOPs/sec rate. Bigger volumes get more credits per second. 3IO credits/second/GB.

33GB = 100 IOPS.
333GB = 1000 IOPS/s

All volumes get 5.4 million IO credits, handles initial workloads very well. (boot)

==Exam: Key take away if you consume more IOPs than the refill value then you have a problem.==

For volumes > 5TB our baseline credit > burst credit. So effectively no credit system.

GP2 good for boot volumes, dev/test.

Elastic volume feature is used to change volume type.

###### GP3

> tldr; no more credit system

Standard 3000IOPS & 125MiB/s

Tends to be cheaper than GP3

4x max throughput of GP2 (1000MiB/s vs 250MiB/s)

Better than GP2 for nearly anything

If you want more than 3000 IOPS you have to add this as an additional extra.

###### io1/2

> tldr; you provision IOPs and throughput irrespective of volume size
> tldr; consistent latency and jitter

4GB - 16TB (io1/io2)
4GB - 64TB (Block Express - BE)

Up to 64,000 IOPS (4x GP2/3)
Block express (preview feature) = 256,000 IOPS
Up to 1,000 MiB/s 
Up to 4,000 MiB/s for BE

You pay for a) size and b) how much IO you provision.

We can run into limits of performance between EC2 instance and the storage.
Influenced by:
- Type of volume
- Type of instance
- Size of instance

io1: 256K IOPS, 7,500MiB/s
io2: 160K IOPS, 4,750MiB/s
io2 BE: 260K IOPS, 7,500MiB/s

Compared to GP2/GP3: 260,000IOPS, 7,000MiB/s

Look at instance max, and storage max to workout effective maximum

One use case for io1/2: Small vols that need high perf
###### EBS HDD Based

> tldr; good for sequential accessed, bad at random access

st1
125GB - 16TB
Max of 500IOPS but! it is measured in 1MB blocks, so max is 500MB/s.
Credit system applies: But it's MB/s not IOPs.
40MB/s Base
500MB/s Burst

sc1
"Cold storage"
Max 250IOPS
Max 250MB/s
12MB/s base
80MB/s burst

Picking between them: If you can tolerate limitations of sc1 pick it, it's cheaper. Otherwise st1. 

###### Instance Store Volumes

> tldr; block storage physically attached to the host
> tldr; highest storage performance in AWS

Included in price of some instances - use it or lose it.

==Exam: Attached at launch time - can't add afterwards==
==Exam: You might as well add it, it's included in the instance price==
==Exam: Temporary storage!==
==Exam: Highest performance available==

If an instance moves between hosts or AZs the data on ephemeral storage is lost.

"Storage optimized" instances are instances that have tuned instance store volumes.

Some instance stores are way higher than EBS.
###### EBS or Instance store?

Persistence: EBS
Resilience: EBS
Storage independent from instance lifecycle: EBS
App has in built replication across many nodes: it depends
High performance: it depends
Super high performance: Instance store volumes
Cost: Instance store (included in instance price)
#### Which EBS volume?

Cheap: SC1 or ST1
Throughput / streaming: ST1
Boot: Not st1 or sc1
gp2/gp3 for requirements up to 16K IOPS
io1/io2 up to 64,000 IOPs
If volumes are put in RAID we can get up to 260,000 IOPS (the max of EBS, this also needs a king sized instance).

![[Images/Pasted image 20230929164042.png]]

#### Transfer family

> tldr; managed service for getting data into aws s3 or efs

Services:
- FTP (unencrypted)
- FTPs (FTP with tls encryption)
- SFTP (file transfer over SSH)
- AS2 (business thingee B2B data)

Identities:
- Service Managed
- Directory Service
- Custom (LAMBDA/APIGATEWAY)

Managed File Transfer Workflows (MFTW)
- Serverless file workflow engine

Main benefit is you can stick stuff in AWS using familiar protocols.

Endpoint types:
- Public
	- only supports SFTP
	- ip address can change
	- use DNS to access, no support for restricting access)
- VPC Internet
	- SFTP & FTPS (and AS2)
	- SGs and NACLs
	- Allocated with an elastic IP to it can be accessed over public internet & via VPC
- VPC Internal
	- Adds FTP support
	- No acesss from public internet

HA: Multi AZ - resilient and scalable
Cost: Cost per hour + Data transfer





