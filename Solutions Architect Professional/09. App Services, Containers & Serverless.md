## App Services, Containers & Serverless

> [!info] Modern application hosting options

> tldr; Virtual Machine virtualisation is inefficient, overhead of OS on every node etc
### Docker Images vs VM

Containers run as a process on a host OS

Main difference between docker image and VM image is Docker image has layers

Layer 1: CentOS image
Layer 2: Updates to CentOS
Layer 3: Adding a custom script

Layers are read only up to this point

Docker container is a running version of an image with an additional read/write layer

Read only layers are shared between multiple containers...
- OS layer isn't duplicated

Docker File -> Generate Image -> Container Registry

### ECS

> tldr; you don't need to create an ec2 instance

Runs in two modes:
- EC2 mode, you see the instances
- Fargate mode, serverless

We need a definition to tell ECS how to run our container
- Container definition
	- Link to the image
	- Ports
- Task definition
	- EC2 vs Fargate mode
	- CPU reqs
	- Memory
- Task Role
	- IAM role to interact with AWS resources
- Service definition
	- How many copies
	- Can deploy multiple tasks with an LB in front
	- Needed for HA
	- Handling restarts

#### EC2 mode vs Fargate Mode

EC2 mode

In EC2 mode, we get an ECS cluster in our VPC
- This runs on EC2 nodes
- ASG allows scaling to meet load reqs
- You need to manage the number of nodes yourself, scaling doesn't happen automatically
- You pay for running nodes

Fargate mode
- Serverless, the fleets is managed by AWS
- Shared isolated Fargate compute platform
- Injected into VPC via Endpoints
- Can be given public addressing

**When should we use ECS or EC2?**

Picking between EC2 and ECS: If you use containers use ECS
- Isolating application
- Reduce overhead

**When should we use EC2 mode and Fargate mode?**
- Use EC2 mode for large workloads when you value cost over effort
	- Management overhead required for EC2 instances
	- Billed for EC2 even with no workload
	- Can use spot mode
- Use Fargate mode for large workloads when you value reduced overhead overhead
	- No in-running costs with no containers
	- Don't have to look after /scale the EC2 instances
- Use Fargate for Small/Burst workloads and Batch/Periodic workloads

### Kubernetes

> tldr; docker with robotic automation and smarts

Control Plane: Scheduling and application deployments
Cluster Nodes: Server that runs the application (workers)

On each of the nodes:
- containerd - run applications
- kubelet - agent to interact with kubernetes control plane

Pods
- smallest unit of computing
- pods can have many containers
- normal to see 1:1 though
- you'd run multiple containers in a pod when they are tightly coupled
- view pods as temporary things

Control Plane:
- Runs kube api
- etcd - kv store for config
- kube-scheduler - assign pods to nodes
- cloud-controller-manager (interfaces with AWS)
- kube-controller manager
	- node controller (monitoring and responding to failed nodes)
	- job controller (running pods to carry out jobs)
	- endpoint controller (links services to pods)
	- service account and token controller (responsible for account and api token creation)

Cluster -> Nodes -> Pods
Service - abstraction over multiple pods 'application'
Jobs - like cron tasks
Ingress - how something external accesses the cluster
- Ingress -> Routing -> Service -> 1+Pods
Ingress Controller - how the ingress actually works, e.g. nginx or or AWS ALB controller using ALB/NLB

Remember there is no persistent storage unless we use Persistent Volumes (PVs)

#### EKS (Elastic Kubernetes Service)

> tldr; AWS managed implementation of Kubernetes

Can be run on AWS, AWS Outposts, or even on prem using AWS Anywhere

Multi-AZ control zone + etcd

Integrates other AWS services
- IAM
- Load Balancers
- VPC
- ECR
- EBS/EFS/FSx for persistent storage

Nodes:
- you an self manage nodes
- managed node groups -> ec2 with automatic provisioning
- fargate pods

To determine node type: Check features you need

==Exam: EKS control plan runs in AWS VPC, not customer VPC==
Worker nodes are in customer VPC
Control plane is injected into customer VPC via ENI

![[Images/eks_101.png]]

### SNS

tdlr; public space aws service that does pub sub for messages

Limit of 256K per message

SNS topics are the base unit

Publisher send messages into a Topic
Topics have subscribers who are delivered those messages
Subscribers receive all messages unless a filter is applied

Types:
- http(s)
- email
- sqs
- mobile push
- sms messages
- lambda

Used across AWS
- e.g. cloud watch alarms

Features:
- Delivery status for some types
	- http(s), lambda, sqs
- Reliable delivery
	- retries
- Regionally resilient
- Highly Available
- Scalable from small to huge workloads
- Supports SSE
- Cross account use via Topic policy

### SQS

> tldr; Public fully managed highly available queues

Standard and FIFO queues

Key difference is order guarantee for FIFO queue

256KB limit

Clients -> Send data to the queue
Clients <- Poll the queue and check for new stuff

Messages are not deleted from queue immediately, they are hidden

Client can explicitly delete the items, but if it doesn't the items will re-appear

Queue handle the process of unhiding the items after the Visibility Timeout

Normal queue processing must delete these items otherwise they re-appear (this should only happen if the processing end fails and doesn't delete)

Otherwise messages go to DLQ (see below)

This enables HA scenarios, messages can be re-read if something fails further upstream

DLQ - Dead Letter Queue
- Problem messages go here
- e.g. If a message is received 5 or more times but never deleted it might go to DLQ
- Special workload looking at DLQ

Queue length:
- ASGs can scale based on this

e.g. User uploads video, it goes to S3 bucket and an item is added for SQS queue for further processing. As number of messages increases, we know we have more videos to process. ASG increases number of EC2 instances to do this quickly.

**Simplified architecture decoupling upload from processing**

Video processing pipeline can scale based on SQS queue backlog

![[Images/sqs_example.png]]

**More complex with multiple processing paths**

We load stuff into an SNS topic to split into multiple SQS queues

![[Images/sns_sqs_fanout.png]]

==Exam: Really remember the SQS fanout architecture==

#### Standard vs FIFO queues

Standard - guaranteed delivery at least 1x but no order guarantee, better performance

##### Standard

As wide as required, like a multi lane highway

At least once delivery - can be more than once!

##### FIFO - Preserves order, slower

Think of this as a single lane highway
300TPs without batching 3000 with batching
Trading performance for order
Exactly once processing - another advantage
==Exam oddity: Fifo queues have to have a fifo suffix to be valid==

Good fit for:
- Sequential systems e.g. command

#### Cost

Based on message request

Even polling an empty queue costs money

1 request can be 1-10 messages up to 64KB total

Short Polling vs Long Polling
- Short is rapid fire and you pay for each hit
- Long  - you get the immediate results and also waits up to 20 seconds until messages arrive, uses fewer requests

#### SQS Extended Client Library

> tldr; work around the 256KB limit without needing to do manual workaround

Used when the message size is over SQS max (>256KB)

You can provide a bigger payload, it gets uploaded to S3, and only a reference is included in message

The receiving end transparently downloads the S3 item

#### SQS Delay Queues

Delay queues add a period of time before items appear in the queue. 

Like Visibility Timeouts only done for the benefit of the client application when we want to introduce a delay to processing.

Basically a way to ensure processing doesn't start until this delay passes... e.g. perhaps some other stuff needs to happen first before procesing continues.

![[Images/sqs_delay_queues.png]]

#### Dead Letter Queue (DLQ)

After X failed attempts messages go to separate queue so they can be dealt with

==Exam: Remember SQS queues have an expiry time for messages==

Messages that go to DLQ don't get a new timestamp - be careful the message doesn't expire

#### Amazon MQ

Like a mixture of SQS and SNS but built on open standard

Managed implementation of AMQ

Key concepts: Topic and Queues

Topics: 1 to many communication channel
Queues: 1-1 communication channel

But some orgs already have MQ on prem. and want to migrate it... 

So we need a standards compliant solution

Unlike SNS/SQS it's not a public service - private networking required

Protocols: AMQP, MQTT, OpenWire, Stomp
#### Wrap-up

==Exam: Choose SNS/SQS if AWS integration is required==
==Exam: Choose AmazonMQ if you are migrating from existing system and can't update application==
==Exam: Remember you need private networking for Amazon MQ==

### Lambda

#### Overview

> tldr; function as a service (FAST)

You provide the code, it runs it and bills you based on how long function runs

You pick a runtime e.g. Python 3.8

You specify how much resource (memory)

- CPU is provided based on memory number supplied
- Every 1769 MB gives you 1vCPU
- Min 128MB Max 10240MB

Think of Lambda as Code + config

You supply a Deployment Package

- Limit 50MB zipped, 250MB unzipped

==Exam: Docker is an antipattern for Lambda - if you hear it in exam don't think Lambda==

Docker images and lambda images are not the same

Custom runtimes = extra languages

Lambda functions are stateless

- Everytime a function is run, the environment is re-created

==Exam: Lamba can only run for 15 minutes / 900 seconds==

Permissions are provided by an *execution role*, attached to the function

Use Cases:

- Serverless Applications (S3, API Gateway, Lambda)
- File Processing (S3, S3 Events, Lambda)
- Database Triggers (DynamoDB, Streams, Lambda)
- Serverless Cron (EventBridge/CWEvents + Lambda)
- Kinesis + Lambda

==Exam: Default execution limit on lambda is 3 seconds==

#### Networking Modes

> tldr; two types of networking, public and VPC

Public is the default

Public Lambda can access Public Services + Public Internet

- But no access to services in a VPC

VPC Lambda

- Lambda goes inside a VPC
- They obey the same rules as anything else in the VPC
- No access outside the VPC unless specifically configured in the VPC
- Lambda functions need EC2 network permissions
- Actually the Lambda function is running in a services VPC and connected into your VPC
  - ENI is created for each combination of Lambda / Security Group / Subnet
  - 90 second initial delay setup, but only the first time!

==Exam: Treat lambda functions in a VPC just like any other service (e.g. internet access needs IGW + natgw from private subnet)==

#### Security

Lambda function needs access to other stuff

A role is created that trusts lambda

Then permissions used to generate temporary permissions the function receives

e.g. Loading from DynamoDB, outputting to S3

##### Resource Policy

> tldr; Like a bucket policy on S3

What services and accounts can Invoke lambda functions?

#### Logging

Uses CloudWatch, CloudWatch Logs & Xray

Logs from Lambda executions are stored in CloudWatchLogs

Metrics - invocation success/failure, retries, latency -> CloudWatch

Lambda can be integrated with X-Ray for distributed tracing

CloudWatch Logs requires permissions via Execution Role

#### Invocation

> tldr Synchronous, Asynchronous, Event Source Mapping

##### Synchronous

Usually used when manually invoked by a human

CLI/API -> Invoke Lambda -> waiting.... -> Result

Errors or retries need to be handled by the client

##### Asynchronous

Typically used when AWS services invoke Lambda functions

Invoke Lambda -> then forget about it

Lambda itself will handle retries

Function must be idempotent (can be run multiple times with no ill effect)

DLQ can be set up for Lambda to send events that can't be processed

Destination can be delivered to other places

- SNS, SQS, Lambda, EventBridge

##### Event Source Mapping

Used when reading from queues, where no 'events' are raised

Hidden component polls queues looking for new data and getting source batches

These are broken up (based on batch size config) and sent to Lambda

Need to be careful of batch size, don't want to overload Lambda and exceed 15 minutes

Lambda doesn't need permissions to the source - events are delivered to Lambda via the ESM which reads from the source

However we do need permissions for the Lambda role to access the source

Consistently failing batches can be send to SQS Queue or SNS Topic

#### Versions

Lambda functions have versions, e.g. v1, v2, v3

Immutable

Has its own ARN

$Latest points at latest version

Aliases can point at a version and are not immutable

- Generally use aliases in production for this reason

#### Startup Times

Lambdas are run in a small container

The execution context needs to be created on demand with dependencies

Cold start

Kind of like spinning up a VM

Can take 100ms or more

Warm start = code reuses the context from the last time

If too much time passes - context is deleted and we have another cold start

##### Provisioned Concurrency

Let AWS know in advance so the exec environments are pre-created

##### Other ways to speed up lambda

Prefill /tmp with some stuff rather than downloading

Create stuff like DB connections outside the lambda function handler

- this decouples it from an individual lambda function

#### Lambda Function Handler

Lambda executions have lifecycles

- INIT creates execution environment
- INVOKE Runs the function handler (Cold start)
- Next INVOKE(s) Warm Start - same environment
- SHUTDOWN - terminates the execution environment

More info: https://docs.aws.amazon.com/lambda/latest/dg/runtimes-context.html

All Lambda functions two parts

- Initialization function (executed once during cold start)
- Handler function (run every single time)
- Aim to put anything that might be reused into the initialization error to reduce overhead

Default name for script is lambda_function (eg. lambda_function.py)

Default initial function name is lambda_handler

#### Lambda Versions

> tldr; Unpublished functions can be changed and deployed... we're just editing the latest version

Version = Published State of current version

Each version is immutable (locked forever)

Qualified ARN -> Points at specific version

Unqualified ARN -> Points at function $LATEST

==Exam: You need to use a Qualified ARN to point at a specific version==

#### Lambda Aliases

> tldr; A way of pointing to a specific version but can be updated

Can't use $LATEST

==Example alias: PROD -> V1 Test -> V2==

API Gateway can be configured to point to an alias which can be updated

#### Lambda Environment Variables

> tldr; Key value pair, 0 or more per Lambda

Associated with $LATEST (can be edited)

If associated with a version, they become read-only

Can be encrypted with KMS

Why do we have them? We can do different stuff based on the env variables, e.g. if Dev then this, if live then that

`import os`

`example of use: print os.environ['ENV']`

#### Lambda Layers

> tldr; If you have big library dependencies, you'd have a massive deployment zip... layers let us split these up

We can share the layer between multiple functions

Common library zip

Deployment zips become small

AWS provides layers for common dependencies

#### Lambda Container Images

> tldr; Uploading a zip to lambda is convenient but doesn't fit with CI/CD processes, containers let us do this

We use existing build processes and load them into lambda

We can test containers locally before deployment

Image includes emulation, this is what allows us to test

Main benefit: more flexibility about how we deploy and test lambda code

#### Lambda and ALB

> tldr; Lambda functions can be interacted with indirectly via an ALB

Lambda function goes in a target group for ALB

The ALB triggers the lambda in response to an HTTP(s) request (request body and metadata)

Interaction is done via JSON

Multi-Value Headers: Allows us to send an array of values through to the Lambda function

#### CloudWatch Events & EventBridge

> tldr; a way of logging things that happen, e.g. ec2 instance being shutdown

Works with various supported services

EventBridge replaces CWEvents, don't use CWEvents for anything new

If X happens, or at Y time(s)... do Z

We have a bus - there's a default one for the account

We create rules and schedules

- Event Pattern rule
- Schedule Rule

EC2 instance changes state -> It goes onto default event bus, EventBridge reads it

When invoked, we can notify a target (e.g. Lambda)

#### API Gateway

> tldr; a way of interacting with applications

- Highly available
- scalable, 
- authorisation
  - integrates with Cognito
  - Or 'lambda authorizer' to do the auth
  - If auth ok, lambda function 
- throttling
- caching
- CORS
- transformations
- OpenAPI spec
- direct integration
  - lambda, step functions, dynamodb, sns etc

Can connect to services/endpoints in AWS or on-premises

Includes a cache

##### Endpoint Types

- Where do the incoming requests go?
- Edge-Optimized
  - Requests go to nearest CloudFront POP
- Regional
  - Clients in the same region
- Private
  - Endpoint accessible via private endpoint in VPC

##### Stages

- APIs are deployed to stages, each stage has one deployment
- This lets us split dev and prod
- Or do canaries
- Each stage is seperate - each has its own config

##### Error codes

- 4XX - Client side error
- 5XX - Server errors, back end issues
- 400 - Bad Request - Generic
- 403 - Access denied - authorizer denies, WAF filtered
- 429 - Throttling
- 502 - Bad gateway exception - bad output returned by lambda function
- 503 - Service Unavailable - backing endpoint offline? Major service issues
- 504 - Integration Failure /Timeout - 29s limit

##### Caching

Defined per stage

TTL 300 seconds by default (0 min 3600s max)

Can be encrypted

Cache size 500MB to 237GB

Calls only made to backend if there's a cache miss

#### API Gateway Methods and Resources

https://129utoasdj.execute-ai.us-east-1.amazonaws.com/dev/listcats

/dev is the stage

/listcats is a resource within the stage

/ is also a resource - the root resource

Then we have **methods** which interact with the resource, e.g. get

#### API Gateway Interactions

> tldr; API gateways job is to act as an intermediary between clients and back end intergrations

Request -> Backend -> Response

In more details:

Method Request phase
- Defines everything about the client's request to the method
- path to use, parameters etc
Integration Request phase
- Parameters from method request are passed through to the integration
- Can involve translation or be passed as is (proxying)
Endpoint 
- headers, 
- status codes etc
Integration Response
- Handles conversion of data from backend endpoint
- Or if proxied passes it straight back
- Includes headers, status codes, method bodies
Method Response
- Handles response to client

#### Backend endpoint integration

MOCK - return response without further processing (no charges, no requirement for backend)
HTTP - API expose HTTP endpoints in the backend, known as http custom integration, have to include request/response translation
HTTP PROXY - Subtype, no translation required, incoming requests passed through
AWS - Allows API to expose AWS services, needs integration request/response with mappings (quite complex)
AWS PROXY - unmodified integration used for Lambda, low overhead integration with Lambda, however lambda function has to handle some translation

![[Images/api_gateway_integrations.png]]

#### Mapping Template

What does this actually do?

- Modify or Rename parameters
- Modify body or headers
- Filtering
- Uses Velocity Template Language (VTL)

Example use case: Interacting with legacy style SOAP API, we need to transform this

https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-integration-types.html

#### Editing API Gateway

All changes have to be deployed out to a stage to take effect

They are not Live by default after you edit them

#### More Stages

Stage names: prod, dev, test or versions v1, v2, v3

v1 might be production
v2 might be BETA - goes to a different backend Lambda function

Stage Variables

e.g. env variable which gets set to stage name

Use stage variable to point to lambda aliases

e.g. Dev stage name -> Dev lambda alias -> $Latest
e.g. Prod stage name -> Prod lambda alias -> V1

Can also use weighting on the lambda stage to do canary testing

#### Swagger and OpenAPI

> tldr; OAS OpenAPI spec defines a standard approach to APIs

Swagger is OpenAPI v2

More recent version is OpenAPI v3

Defines endpoints /listcats and operations GET /listcats

Input / Output parameters and Auth methods

License terms, contact info

API Gateway can export the format and generate it

Stages -> Dev -> Export 

Can export/import and API without manually creating

Note: Doesn't handle perms for lambda executions

#### Step Functions

> tldr; addresses some of the design limitations with lambdas, around long running jobs

Usually used for backend services

A way of chaining lambda functions together

Lambda is not designed for long time running stuff, it's designed for small execution tasks

State machine

A state is a 'thing' that occurs inside a step machine... can do something or decide something

Max duration of execution = 1 year...

Standard (default, 1 year) and Express workflow (<=5mins)

Amazon States Language - ASL

IAM role is used for permissions

##### States

Succeed & Fail
Wait
Choice -- different path depending on input
Parallel -- two branches, based on choice
Map -- for each item, map state performs an action
Task -- The actual work, e.g. kick off a lambda function, insert into DDB, upload to S3

State machine doesn't do work - it co-ordinates

#### Simple Workflow Service (SWF)

> tldr; a bit like Step functions but older and not serverless

Based on EC2 instances

Prefer Step Functions unless there is a specific need for SWF (~90% of use cases don't need SWF)

1 year maximum duration like Step Function

When to choose SWF?
- 'AWS Flow Framework' - needs SWF
- External Signals to intervene in processes - SWF
- Child flows that return to parent - SWF
- Bespoke / Complex decisions (SWF custom decider applications)
- Interactions with Mechanical Turk

![[Images/swf_example.png]]
#### Mechanical Turk

> tldr; a marketplace that allows outsourcing of tasks to human workers... big pool of users ready to complete tasks

Pay per task service for tasks that humans are better at performing than computers

Qualifications can limit pool of workers

Pay per task co-ordinated through APIs

#### Elastic Transcoder & Media Convert

> tldr; niche product used in media based serverless architectures

Media Convert is Elastic Transcoder v2, prefer it

File based video transcoding services

Add job to queue - product handles the transcoding and puts in S3 bucket

Media Convert supports EventBridge - powerful advantage over ET

Use these products when:
- You want a managed solution for converting media
- You want a serverless architecture
- Media Convert is better
	- ET does support some codecs MC doesn't

#### IOT

> tldr; group of services that handle data flows between lots of iot devices

e.g. lights, robotic vaccum cleaner

Device Shadow functionality
- Virtual representations of devices that may have sporadic connectivity
- A proxy for a real device to avoid hassle of connecting to the devices

IOT rules
- If certain things happen, action is performed
- E.g. temperature gets too hot

Kinesis / Data Firehose -- has functionality for IOT ingestion

#### Greengrass

> tldr; Extends some services to the Edge, e.g. the Industrial space where a set of windmills run from.

e.g. some compute, messaging, data management, sync and ml capabilities to enable IOT functionality for local operation

Often IOT things struggle with communication into the network

Greengrass brings the functionality closer and enables more realtime things, without worrying about latency

#### SAM - Serverless Application Model

> tldr; open Source Framework for building serverless applications

- Front end code & Assets - S3 & Cloudfront
- API Endpoint - API Gateway
- Compute - Lambda
- Database - DynamoDB

SAM template is a bit like CloudFormation
Enables local lambda invocation for testing
Then deployed into AWS

![[Images/sam_example.png]]
